import os
import subprocess
import sys
import time
import platform
import requests
from typing import List, Dict, Any, Optional
from pathlib import Path

# Verificar y manejar dependencias
try:
    from llama_index.core import Settings, VectorStoreIndex, SimpleDirectoryReader
    from llama_index.core.agent import ReActAgent
    from llama_index.core.tools import FunctionTool, ToolMetadata
    from llama_index.llms.ollama import Ollama
except ImportError:
    print("üîÑ Instalando dependencias necesarias...")
    subprocess.check_call([sys.executable, "-m", "pip", "install", "llama-index", "llama-index-llms-ollama", "requests"])
    print("‚úÖ Dependencias instaladas correctamente.")
    from llama_index.core import Settings, VectorStoreIndex, SimpleDirectoryReader
    from llama_index.core.agent import ReActAgent
    from llama_index.core.tools import FunctionTool, ToolMetadata
    from llama_index.llms.ollama import Ollama


# Clase principal que maneja todo el sistema multiagente
class MultiAgentSystem:
    def __init__(self, model_name="phi", data_dir="./data", temperatura=0.7, timeout=120.0, verbose=True):
        """
        Inicializa el sistema multiagente.
        
        Args:
            model_name: Nombre del modelo de Ollama a utilizar
            data_dir: Directorio donde se almacenar√°n los documentos de conocimiento
            temperatura: Temperatura para el modelo (mayor valor = m√°s creativo)
            timeout: Tiempo m√°ximo de espera para respuestas
            verbose: Si se deben mostrar logs detallados
        """
        self.model_name = model_name
        self.data_dir = data_dir
        self.temperatura = temperatura
        self.timeout = timeout
        self.verbose = verbose
        
        self.llm = None
        self.indice = None
        self.recuperador = None
        self.coordinador = None
        
        # Crear directorio de datos si no existe
        Path(data_dir).mkdir(exist_ok=True)
        
        print(f"üöÄ Iniciando Sistema Multiagente con modelo '{model_name}'")
    
    def instalar_ollama(self) -> bool:
        """Instala Ollama en el sistema si no est√° presente"""
        sistema = platform.system().lower()
        
        print("üîÑ Instalando Ollama...")
        
        try:
            if sistema == "linux":
                # Instalaci√≥n en Linux
                print("Detectado sistema Linux. Instalando Ollama...")
                subprocess.run(
                    "curl -fsSL https://ollama.com/install.sh | sh",
                    shell=True,
                    check=True
                )
                
            elif sistema == "darwin":  # macOS
                # Instalaci√≥n en macOS
                print("Detectado sistema macOS. Instalando Ollama...")
                
                # Verificar si Homebrew est√° instalado
                try:
                    subprocess.run(["brew", "--version"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
                    # Instalar con Homebrew
                    subprocess.run(["brew", "install", "ollama"], check=True)
                except (subprocess.SubprocessError, FileNotFoundError):
                    # Si no hay Homebrew, usar el script oficial
                    subprocess.run(
                        "curl -fsSL https://ollama.com/install.sh | sh",
                        shell=True,
                        check=True
                    )
                    
            elif sistema == "windows":
                # Instalaci√≥n en Windows
                print("Detectado sistema Windows. Descargando instalador de Ollama...")
                
                # URL del instalador de Windows
                url = "https://ollama.com/download/windows"
                
                # Descargar el instalador
                installer_path = os.path.expanduser("~/Downloads/ollama-installer.exe")
                response = requests.get(url)
                with open(installer_path, 'wb') as f:
                    f.write(response.content)
                
                print(f"Instalador descargado en {installer_path}")
                print("Ejecutando instalador. Por favor complete la instalaci√≥n cuando aparezca el asistente...")
                
                # Ejecutar el instalador
                subprocess.run([installer_path], check=True)
                
                # Esperar a que el usuario complete la instalaci√≥n
                print("Esperando a que se complete la instalaci√≥n...")
                time.sleep(10)  # Dar tiempo para que el instalador se inicie
                
                # Verificar si el servicio de Ollama est√° en ejecuci√≥n
                max_attempts = 5
                for attempt in range(max_attempts):
                    try:
                        subprocess.run(["ollama", "list"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=False)
                        print("‚úÖ Ollama instalado correctamente en Windows")
                        break
                    except FileNotFoundError:
                        if attempt < max_attempts - 1:
                            print(f"Esperando a que Ollama est√© disponible... ({attempt+1}/{max_attempts})")
                            time.sleep(10)
                        else:
                            print("‚ö†Ô∏è  La instalaci√≥n puede estar en progreso. Si este script falla:")
                            print("1. Complete la instalaci√≥n de Ollama manualmente")
                            print("2. Aseg√∫rese de que Ollama est√© en ejecuci√≥n")
                            print("3. Vuelva a ejecutar este script")
            else:
                print(f"‚ùå Sistema operativo no compatible: {sistema}")
                print("Por favor, instale Ollama manualmente desde: https://ollama.ai/")
                return False
            
            # Verificar si la instalaci√≥n fue exitosa
            try:
                # Dar tiempo a que el servicio se inicie
                time.sleep(3)
                
                # Intentar ejecutar comando de Ollama
                result = subprocess.run(
                    ["ollama", "list"],
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    text=True,
                    check=False
                )
                
                if result.returncode == 0:
                    print("‚úÖ Ollama instalado correctamente y funcionando")
                    return True
                else:
                    print(f"‚ö†Ô∏è  Ollama instalado pero presenta errores: {result.stderr}")
                    return False
                    
            except FileNotFoundError:
                print("‚ö†Ô∏è  Ollama instalado pero no se encuentra en el PATH del sistema")
                print("Recomendaci√≥n: Reinicie su terminal o computadora y vuelva a intentarlo")
                return False
                
        except Exception as e:
            print(f"‚ùå Error durante la instalaci√≥n de Ollama: {str(e)}")
            print("Por favor, instale Ollama manualmente desde: https://ollama.ai/")
            return False
    
    def verificar_ollama(self) -> bool:
        """Verifica si Ollama est√° instalado y disponible. Si no, intenta instalarlo"""
        try:
            result = subprocess.run(
                ["ollama", "list"], 
                stdout=subprocess.PIPE, 
                stderr=subprocess.PIPE, 
                text=True,
                check=False
            )
            
            if result.returncode != 0:
                print("‚ùå Ollama est√° instalado pero no funciona correctamente.")
                print(f"Error: {result.stderr}")
                
                # Intentar reparar o reinstalar
                return self.instalar_ollama()
                
            print("‚úÖ Ollama est√° instalado y funcionando correctamente")
            return True
            
        except FileNotFoundError:
            print("‚ùå Ollama no est√° instalado en este sistema.")
            return self.instalar_ollama()
    
    def verificar_modelo(self) -> bool:
        """Verifica si el modelo solicitado est√° disponible y lo descarga si es necesario"""
        try:
            # Verificar si el modelo ya est√° descargado
            result = subprocess.run(
                ["ollama", "list"], 
                stdout=subprocess.PIPE, 
                stderr=subprocess.PIPE, 
                text=True,
                encoding="utf-8",  # Forzar codificaci√≥n UTF-8
                check=False
            )
            
            if self.model_name in result.stdout:
                print(f"‚úÖ Modelo '{self.model_name}' ya est√° disponible")
                return True
            else:
                print(f"üîÑ Descargando modelo '{self.model_name}'...")
                download = subprocess.run(
                    ["ollama", "pull", self.model_name],
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    text=True,
                    encoding="utf-8",  # Forzar codificaci√≥n UTF-8
                    check=False
                )
                
                if download.returncode != 0:
                    print(f"‚ùå Error al descargar el modelo: {download.stderr}")
                    return False
                
                print(f"‚úÖ Modelo '{self.model_name}' descargado correctamente")
                return True
                
        except Exception as e:
            print(f"‚ùå Error al verificar/descargar el modelo: {str(e)}")
            return False
    
    def crear_documentos_ejemplo(self):
        """Crea documentos de ejemplo si no existen"""
        if not os.listdir(self.data_dir):
            print("üìÑ Creando archivos de ejemplo...")
            
            examples = {
                "python.txt": """
                Python es un lenguaje de programaci√≥n interpretado de alto nivel creado por Guido van Rossum en 1991.
                Es conocido por su filosof√≠a de dise√±o que enfatiza la legibilidad del c√≥digo con su notable uso de espacios en blanco.
                Python soporta m√∫ltiples paradigmas de programaci√≥n, incluyendo programaci√≥n estructurada, orientada a objetos y funcional.
                Es ampliamente utilizado en ciencia de datos, inteligencia artificial, desarrollo web y automatizaci√≥n.
                """,
                
                "agents.txt": """
                Los agentes de IA son sistemas de software que pueden percibir su entorno, tomar decisiones y actuar para lograr objetivos espec√≠ficos.
                Un agente utiliza modelos de lenguaje (LLMs) como su "cerebro" para procesar informaci√≥n y tomar decisiones.
                Los multiagentes son sistemas donde varios agentes especializados colaboran para resolver tareas complejas.
                Cada agente puede tener un rol espec√≠fico: b√∫squeda de informaci√≥n, an√°lisis, creatividad, etc.
                El flujo t√≠pico incluye: recibir una solicitud, planificar, ejecutar acciones mediante herramientas, y entregar resultados.
                """,
                
                "rag.txt": """
                RAG (Retrieval Augmented Generation) es una t√©cnica que combina la recuperaci√≥n de informaci√≥n con la generaci√≥n de texto.
                En un sistema RAG, cuando se recibe una consulta, primero se buscan documentos o fragmentos relevantes en una base de conocimiento.
                Luego, estos fragmentos se proporcionan como contexto a un modelo de lenguaje para generar una respuesta informada.
                RAG mejora la precisi√≥n de las respuestas al proporcionar informaci√≥n espec√≠fica y actualizada.
                Tambi√©n ayuda a reducir las "alucinaciones" o la generaci√≥n de informaci√≥n incorrecta por parte de los modelos.
                """,
                
                "llms.txt": """
                Los Large Language Models (LLMs) son modelos de inteligencia artificial entrenados con enormes cantidades de texto.
                Estos modelos pueden generar texto, traducir idiomas, escribir diferentes tipos de contenido creativo y responder preguntas.
                Ejemplos populares incluyen GPT, LLaMA, Mistral, Phi y Claude.
                Los LLMs locales son modelos que se pueden ejecutar en tu propio ordenador o servidor, sin necesidad de conexi√≥n a la nube.
                Ollama es una herramienta que permite ejecutar LLMs de forma local con una configuraci√≥n m√≠nima.
                """
            }
            
            for filename, content in examples.items():
                with open(os.path.join(self.data_dir, filename), "w", encoding="utf-8") as f:
                    f.write(content)
            
            print("‚úÖ Archivos de ejemplo creados correctamente")
    
    def configurar_modelo(self):
        """Configura el modelo LLM de Ollama"""
        try:
            self.llm = Ollama(
                model=self.model_name,
                temperature=self.temperatura,
                request_timeout=self.timeout
            )
            Settings.llm = self.llm
            print("‚úÖ Modelo configurado correctamente")
            return True
        except Exception as e:
            print(f"‚ùå Error al configurar el modelo: {str(e)}")
            return False
    
    def crear_indice(self):
        """Crea un √≠ndice vectorial con los documentos del directorio de datos"""
        try:
            documentos = SimpleDirectoryReader(self.data_dir).load_data()
            self.indice = VectorStoreIndex.from_documents(documentos)
            self.recuperador = self.indice.as_retriever(similarity_top_k=2)
            print(f"‚úÖ √çndice creado con {len(documentos)} documentos")
            return True
        except Exception as e:
            print(f"‚ùå Error al crear el √≠ndice: {str(e)}")
            
            # Crear un recuperador simulado si falla la creaci√≥n del √≠ndice real
            def recuperador_simulado(query):
                return [{"text": "No se pudo crear un √≠ndice real, esta es una respuesta simulada."}]
            
            self.recuperador = type('obj', (object,), {
                'retrieve': recuperador_simulado
            })
            return False
    
    def definir_herramientas(self):
        """Define las herramientas que utilizar√°n los agentes"""
        # Herramienta de b√∫squeda de conocimiento
        conocimiento_tool = FunctionTool.from_defaults(
            name="buscador_conocimiento",
            fn=self.buscar_conocimiento,
            description="Busca informaci√≥n en la base de conocimientos interna"
        )
        
        # Herramienta de calculadora
        calculadora_tool = FunctionTool.from_defaults(
            name="calculadora",
            fn=self.calculadora,
            description="Realiza operaciones matem√°ticas b√°sicas como suma, resta, multiplicaci√≥n y divisi√≥n"
        )
        
        # Herramienta de b√∫squeda web simulada
        web_tool = FunctionTool.from_defaults(
            name="buscador_web",
            fn=self.buscar_web_simulada,
            description="Busca informaci√≥n en la web (simulado)"
        )
        
        print("‚úÖ Herramientas base creadas correctamente")
        return conocimiento_tool, calculadora_tool, web_tool
    
    def crear_agentes(self, conocimiento_tool, calculadora_tool, web_tool):
        """Crea los agentes especializados y el coordinador"""
        try:
            # Agente investigador (especializado en b√∫squeda de informaci√≥n)
            agente_investigador = ReActAgent.from_tools(
                [conocimiento_tool, web_tool],
                llm=self.llm,
                verbose=self.verbose,
                system_prompt="""
                Eres un agente investigador especializado en buscar y recuperar informaci√≥n.
                Tu objetivo es encontrar datos precisos y relevantes utilizando las herramientas disponibles.
                Primero intenta buscar en la base de conocimientos interna, y si no encuentras informaci√≥n,
                utiliza el buscador web. Presenta la informaci√≥n de manera clara y organizada.
                """
            )
            
            # Agente analista (especializado en matem√°ticas y an√°lisis)
            agente_analista = ReActAgent.from_tools(
                [calculadora_tool],
                llm=self.llm,
                verbose=self.verbose,
                system_prompt="""
                Eres un agente analista especializado en matem√°ticas y an√°lisis de datos.
                Tu objetivo es realizar c√°lculos precisos y analizar informaci√≥n num√©rica.
                Utiliza la calculadora para realizar operaciones matem√°ticas cuando sea necesario.
                Explica tus razonamientos paso a paso para que sean f√°ciles de entender.
                """
            )
            
            print("‚úÖ Agentes especializados creados correctamente")
            
            # Convertir los agentes en herramientas para el coordinador
            investigador_tool = FunctionTool.from_defaults(
                name="investigador",
                fn=lambda query: agente_investigador.chat(query).response,
                description="Consulta al agente investigador para buscar informaci√≥n"
            )
            
            analista_tool = FunctionTool.from_defaults(
                name="analista",
                fn=lambda query: agente_analista.chat(query).response,
                description="Consulta al agente analista para realizar an√°lisis matem√°ticos"
            )
            
            # Crear el agente coordinador
            self.coordinador = ReActAgent.from_tools(
                [investigador_tool, analista_tool],
                llm=self.llm,
                verbose=self.verbose,
                system_prompt="""
                Eres un agente coordinador que gestiona un equipo de agentes especializados.
                Tu objetivo es resolver las consultas del usuario delegando tareas espec√≠ficas a los agentes adecuados:
                
                - Para b√∫squeda de informaci√≥n y consultas generales, utiliza al agente "investigador"
                - Para c√°lculos matem√°ticos y an√°lisis num√©ricos, utiliza al agente "analista"
                
                Analiza cada consulta para determinar qu√© agente deber√≠a manejarla, o si se requiere la colaboraci√≥n
                de varios agentes. Organiza y sintetiza las respuestas de los agentes para proporcionar una
                respuesta final coherente y completa al usuario.
                """
            )
            
            print("‚úÖ Sistema multiagente creado correctamente")
            return True
        except Exception as e:
            print(f"‚ùå Error al crear los agentes: {str(e)}")
            return False
    
    def buscar_conocimiento(self, query: str) -> str:
        """
        Busca informaci√≥n en la base de conocimientos.
        
        Args:
            query: La consulta o pregunta del usuario
            
        Returns:
            Informaci√≥n relevante encontrada en la base de conocimientos
        """
        try:
            resultados = self.recuperador.retrieve(query)
            if not resultados:
                return "No se encontr√≥ informaci√≥n relevante en la base de conocimientos."
            
            textos = [node.text for node in resultados]
            return "\n\n".join(textos)
        except Exception as e:
            return f"Error al buscar en la base de conocimientos: {str(e)}"
    
    def calculadora(self, operacion: str, a: float, b: float) -> str:
        """
        Realiza operaciones matem√°ticas b√°sicas.
        
        Args:
            operacion: Tipo de operaci√≥n (suma, resta, multiplicacion, division, potencia, raiz)
            a: Primer n√∫mero
            b: Segundo n√∫mero
            
        Returns:
            El resultado de la operaci√≥n
        """
        try:
            if operacion.lower() == "suma":
                return f"{a} + {b} = {a + b}"
            elif operacion.lower() == "resta":
                return f"{a} - {b} = {a - b}"
            elif operacion.lower() == "multiplicacion":
                return f"{a} * {b} = {a * b}"
            elif operacion.lower() == "division":
                if b == 0:
                    return "Error: No se puede dividir por cero"
                return f"{a} / {b} = {a / b}"
            elif operacion.lower() == "potencia":
                return f"{a} ^ {b} = {a ** b}"
            elif operacion.lower() == "raiz":
                if a < 0 and b % 2 == 0:
                    return "Error: No se puede calcular ra√≠z par de un n√∫mero negativo"
                return f"Ra√≠z {b} de {a} = {a ** (1/b)}"
            elif operacion.lower() == "modulo" or operacion.lower() == "resto":
                return f"{a} % {b} = {a % b}"
            else:
                return (f"Operaci√≥n '{operacion}' no reconocida. Opciones v√°lidas: " 
                        f"suma, resta, multiplicacion, division, potencia, raiz, modulo")
        except Exception as e:
            return f"Error en la calculadora: {str(e)}"
    
    def buscar_web_simulada(self, query: str) -> str:
        """
        Simula una b√∫squeda en la web (para evitar dependencias externas).
        
        Args:
            query: La consulta o b√∫squeda
            
        Returns:
            Resultados simulados de la b√∫squeda
        """
        base_conocimiento = {
            "python": "Python es un lenguaje de programaci√≥n vers√°til usado en ciencia de datos, web y automatizaci√≥n.",
            "javascript": "JavaScript es un lenguaje de programaci√≥n para desarrollo web que permite crear p√°ginas interactivas.",
            "llama index": "LlamaIndex es una biblioteca para crear aplicaciones con LLMs y fuentes de datos personalizadas.",
            "agentes": "Los agentes de IA son sistemas aut√≥nomos que perciben, deciden y act√∫an para lograr objetivos.",
            "rag": "RAG (Retrieval Augmented Generation) combina recuperaci√≥n de datos con generaci√≥n de texto.",
            "ollama": "Ollama es una herramienta para ejecutar modelos de lenguaje de forma local sin necesidad de servicios en la nube.",
            "phi": "Phi es un modelo de lenguaje peque√±o desarrollado por Microsoft, dise√±ado para funcionar en ordenadores personales con recursos limitados.",
            "llama": "LLaMA (Large Language Model Meta AI) es una familia de modelos de lenguaje desarrollados por Meta AI (Facebook).",
            "mistral": "Mistral es una familia de modelos de lenguaje desarrollados por Mistral AI, con versiones optimizadas para diferentes tama√±os y casos de uso.",
            "gemma": "Gemma es un modelo de lenguaje desarrollado por Google, optimizado para ejecutarse en computadoras con recursos limitados.",
            "cpu": "La CPU (Unidad Central de Procesamiento) es el 'cerebro' del ordenador que ejecuta instrucciones.",
            "gpu": "La GPU (Unidad de Procesamiento Gr√°fico) est√° optimizada para operaciones paralelas y es ideal para IA.",
            "multiagente": "Un sistema multiagente es una red de agentes de IA que colaboran para resolver problemas complejos."
        }
        
        resultados = []
        for keyword, info in base_conocimiento.items():
            if keyword.lower() in query.lower():
                resultados.append(info)
        
        if not resultados:
            return f"No se encontr√≥ informaci√≥n sobre: {query}"
        
        return "\n".join(resultados)
    
    def responder(self, consulta: str) -> str:
        """
        Procesa una consulta del usuario utilizando el sistema multiagente.
        
        Args:
            consulta: La consulta o pregunta del usuario
            
        Returns:
            Respuesta generada por el sistema multiagente
        """
        if self.coordinador is None:
            return "Error: El sistema multiagente no est√° inicializado correctamente."
        
        if self.verbose:
            print(f"\nüìù Consulta recibida: {consulta}")
            print("ü§ñ Procesando con el sistema multiagente...")
        
        try:
            start_time = time.time()
            respuesta = self.coordinador.chat(consulta)
            elapsed_time = time.time() - start_time
            
            if self.verbose:
                print(f"‚è±Ô∏è Tiempo de respuesta: {elapsed_time:.2f} segundos")
            
            return respuesta.response
        except Exception as e:
            return f"Error al procesar la consulta: {str(e)}"
    
    def inicializar(self) -> bool:
        # Comprobar Ollama
        # if not self.verificar_ollama():
        #     return False
        
        # Comprobar y descargar modelo si es necesario
        if not self.verificar_modelo():
            return False
        
        # Configurar modelo
        if not self.configurar_modelo():
            return False
        
        # Crear documentos de ejemplo
        self.crear_documentos_ejemplo()
        
        # Crear √≠ndice vectorial
        self.crear_indice()
        
        # Definir herramientas
        conocimiento_tool, calculadora_tool, web_tool = self.definir_herramientas()
        
        # Crear agentes
        if not self.crear_agentes(conocimiento_tool, calculadora_tool, web_tool):
            return False
        
        print("\n" + "="*80)
        print("üöÄ Sistema multiagente inicializado correctamente")
        print("="*80)
        return True
    
    def ejecutar_ejemplos(self):
        """Ejecuta ejemplos de consultas para demostrar el funcionamiento"""
        print("\n" + "="*80)
        print("üß™ Ejecutando ejemplos de consultas")
        print("="*80)
        
        ejemplos = [
            "¬øQu√© es Python y para qu√© se utiliza?",
            "Necesito calcular 23.5 * 17.8",
            "¬øQu√© es RAG y puedes calcular cu√°nto es 15 al cuadrado?"
        ]
        
        for i, consulta in enumerate(ejemplos, 1):
            print(f"\nEjemplo {i}: {consulta}")
            respuesta = self.responder(consulta)
            print(f"\nRespuesta: {respuesta}")
            time.sleep(1)  # Breve pausa entre ejemplos
        
        print("\n" + "="*80)
        print("‚úÖ Ejemplos completados")
        print("="*80)
    
    def iniciar_interfaz_consola(self):
        """Inicia una interfaz interactiva por consola"""
        print("\nü§ñ Asistente Multiagente LlamaIndex")
        print("Escribe 'salir' para terminar")
        print("Escribe 'ayuda' para ver comandos disponibles")
        
        while True:
            try:
                consulta = input("\nüß† Consulta: ")
                
                # Comandos especiales
                if consulta.lower() in ["salir", "exit", "quit", "q"]:
                    print("¬°Hasta luego!")
                    break
                elif consulta.lower() in ["ayuda", "help", "h", "?"]:
                    print("\nüìñ Comandos disponibles:")
                    print("- salir/exit/quit: Terminar la aplicaci√≥n")
                    print("- ayuda/help: Mostrar esta ayuda")
                    print("- modelos: Listar modelos disponibles")
                    print("- cambiar [modelo]: Cambiar al modelo especificado")
                    print("- status: Mostrar estado del sistema")
                    continue
                elif consulta.lower() == "modelos":
                    try:
                        result = subprocess.run(
                            ["ollama", "list"], 
                            stdout=subprocess.PIPE, 
                            stderr=subprocess.PIPE, 
                            text=True,
                            check=False
                        )
                        print("\nüìã Modelos disponibles en Ollama:")
                        print(result.stdout)
                    except Exception as e:
                        print(f"Error al listar modelos: {str(e)}")
                    continue
                elif consulta.lower().startswith("cambiar "):
                    nuevo_modelo = consulta.split(" ", 1)[1].strip()
                    print(f"üîÑ Cambiando al modelo '{nuevo_modelo}'...")
                    
                    self.model_name = nuevo_modelo
                    if self.verificar_modelo() and self.configurar_modelo():
                        print(f"‚úÖ Modelo cambiado a '{nuevo_modelo}' correctamente")
                        # Recrear los agentes con el nuevo modelo
                        conocimiento_tool, calculadora_tool, web_tool = self.definir_herramientas()
                        self.crear_agentes(conocimiento_tool, calculadora_tool, web_tool)
                    else:
                        print(f"‚ùå No se pudo cambiar al modelo '{nuevo_modelo}'")
                    continue
                elif consulta.lower() == "status":
                    print("\nüìä Estado del sistema:")
                    print(f"- Modelo actual: {self.model_name}")
                    print(f"- Temperatura: {self.temperatura}")
                    print(f"- Directorio de datos: {self.data_dir}")
                    print(f"- Sistema multiagente activo: {'S√≠' if self.coordinador else 'No'}")
                    continue
                    
                # Procesar consulta normal
                respuesta = self.responder(consulta)
                print(f"\nü§ñ Respuesta: {respuesta}")
                
            except KeyboardInterrupt:
                print("\n¬°Hasta luego!")
                break
            except Exception as e:
                print(f"Error: {str(e)}")


# Funci√≥n principal
def main():
    # Configurar modelos disponibles
    modelos_disponibles = ["phi", "llama3", "mistral", "gemma"]
    modelo_predeterminado = "phi3"
    
    # Elegir modelo
    if len(sys.argv) > 1 and sys.argv[1] in modelos_disponibles:
        modelo = sys.argv[1]
    else:
        print(f"\nüìã Modelos disponibles: {', '.join(modelos_disponibles)}")
        print(f"Usando modelo predeterminado: {modelo_predeterminado}")
        modelo = modelo_predeterminado
    
    # Inicializar el sistema
    sistema = MultiAgentSystem(
        model_name=modelo,
        temperatura=0.7,  # Valor predeterminado para equilibrar creatividad y precisi√≥n
        verbose=True      # Mostrar logs detallados
    )
    
    # Inicializar el sistema multiagente
    if sistema.inicializar():
        # Ejecutar ejemplos demostrativos
        if len(sys.argv) > 2 and sys.argv[2].lower() == "--ejemplos":
            sistema.ejecutar_ejemplos()
        
        # Iniciar la interfaz de consola interactiva
        sistema.iniciar_interfaz_consola()
    else:
        print("‚ùå No se pudo inicializar el sistema multiagente correctamente.")
        print("Por favor, verifica la instalaci√≥n de Ollama y los modelos.")
        sys.exit(1)

# Punto de entrada cuando se ejecuta como script
if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nüëã Programa terminado por el usuario.")
    except Exception as e:
        print(f"\n‚ùå Error inesperado: {str(e)}")
        sys.exit(1)